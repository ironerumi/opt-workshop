{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import datetime as dt\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from dask import compute, delayed\n",
    "import datarobot as dr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pulumi\n",
    "import pulumi_datarobot as datarobot\n",
    "from pulumi import automation as auto\n",
    "\n",
    "if not os.getenv(\"DATAROBOT_NOTEBOOK_IMAGE\"):\n",
    "    print(\"not running in DataRobot Notebook\")\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(\"../.env\", override=True)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "client = dr.Client()\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_colwidth\", 1000)\n",
    "pd.set_option(\"display.precision\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# モデル作成\n",
    "input_path = \"../data/\"\n",
    "file_name = \"opt_steel_strength.csv\"\n",
    "targets = [\"降伏強度\", \"引張強度\"]\n",
    "group_col = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def __run_autopilot(target, df, group_col):\n",
    "    project = dr.Project.create(df, project_name=f\"opt-{target}\")\n",
    "\n",
    "    ao = dr.AdvancedOptions()\n",
    "    if group_col != False:\n",
    "        pm = dr.GroupCV(holdout_pct=0, partition_key_cols=[group_col], reps=5)\n",
    "    else:\n",
    "        pm = dr.RandomCV(holdout_pct=0, reps=5)\n",
    "\n",
    "    project.analyze_and_model(\n",
    "        worker_count=-1,\n",
    "        target=target,\n",
    "        mode=\"quick\",\n",
    "        partitioning_method=pm,\n",
    "        advanced_options=ao,\n",
    "        max_wait=36000,\n",
    "    )\n",
    "\n",
    "    return project\n",
    "\n",
    "\n",
    "def __wait_for_cv(projects):\n",
    "    for i in range(len(projects)):\n",
    "        try:\n",
    "            project = dr.Project.get(project_id=projects[i - 1].id)\n",
    "            jobs_list = project.get_all_jobs()\n",
    "            for job in jobs_list:\n",
    "                job.wait_for_completion(max_wait=60000)\n",
    "            print(\"Project \" + targets[i] + \" completed running autopilot\")\n",
    "        except:\n",
    "            print(\"Project \" + targets[i] + \" occured error\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(input_path + file_name)\n",
    "df.to_csv(input_path + \"feature.csv\", index=False)\n",
    "df_feature = df.drop(targets, axis=1)\n",
    "\n",
    "delayed_dr_projects = []\n",
    "for i in range(len(targets)):\n",
    "    df_ = df_feature.copy()\n",
    "    df_[targets[i]] = df[targets[i]]\n",
    "    temp = delayed(__run_autopilot)(targets[i], df_, group_col)\n",
    "    delayed_dr_projects.append(temp)\n",
    "\n",
    "projects = compute(delayed_dr_projects)[0]\n",
    "\n",
    "__wait_for_cv(projects)\n",
    "\n",
    "models = [project.get_top_model() for project in projects]\n",
    "for model in models:\n",
    "    print(f\"Project {model.project_id}, Top model: {model.id}, {model.model_type}\")\n",
    "model_ids = [model.id for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# create quantile project\n",
    "\n",
    "def __run_autopilot(target, df, group_col, quantile):\n",
    "    client = dr.Client()\n",
    "    project = dr.Project.create(df, project_name=f\"opt-{target}-{quantile}\")\n",
    "    project_id = project.id\n",
    "\n",
    "    payload = {\n",
    "        \"target\": target,\n",
    "        \"mode\": \"quick\",\n",
    "        \"targetType\": \"Regression\",\n",
    "        \"cvMethod\": \"random\",\n",
    "        \"holdoutPct\": 20,\n",
    "        \"validationType\": \"CV\",\n",
    "        \"reps\": 5,\n",
    "        \"metric\": \"Quantile Loss\",\n",
    "        \"blendBestModels\": False,\n",
    "        \"prepareModelForDeployment\": True,\n",
    "        \"quantileLevel\": quantile,\n",
    "    }\n",
    "    response = client.patch(f\"projects/{project_id}/aim/\", json=payload)\n",
    "    assert response.status_code == 202\n",
    "    project.set_worker_count(-1)\n",
    "\n",
    "    return project\n",
    "\n",
    "\n",
    "def __wait_for_cv(projects):\n",
    "    for i in range(len(projects)):\n",
    "        try:\n",
    "            project = dr.Project.get(project_id=projects[i - 1].id)\n",
    "            jobs_list = project.get_all_jobs()\n",
    "            for job in jobs_list:\n",
    "                job.wait_for_completion(max_wait=60000)\n",
    "            print(\"Project \" + targets[i] + \" completed running autopilot\")\n",
    "        except:\n",
    "            print(\"Project \" + targets[i] + \" occured error\")\n",
    "\n",
    "df = pd.read_csv(input_path + file_name)\n",
    "df.to_csv(input_path + \"feature.csv\", index=False)\n",
    "df_feature = df.drop(targets, axis=1)\n",
    "\n",
    "delayed_dr_projects = []\n",
    "for q in [0.25,0.75]:\n",
    "    df_ = df_feature.copy()\n",
    "    df_[\"降伏強度\"] = df[\"降伏強度\"]\n",
    "    temp = delayed(__run_autopilot)(\"降伏強度\", df_, group_col, q)\n",
    "    delayed_dr_projects.append(temp)\n",
    "\n",
    "projects = compute(delayed_dr_projects)[0]\n",
    "\n",
    "__wait_for_cv(projects)\n",
    "for project in projects:\n",
    "    project.wait_for_autopilot(check_interval=30)\n",
    "models = [project.get_top_model() for project in projects]\n",
    "for model in models:\n",
    "    print(f\"Project {model.project_id}, Top model: {model.id}, {model.model_type}\")\n",
    "model_quant_ids = [model.id for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecase_id = os.getenv(\"DATAROBOT_DEFAULT_USE_CASE\")\n",
    "model_ids = [\"67bb463d7bb3e096b730cbf9\", \"67bb46747b6a561d75815d5e\"]\n",
    "model_quant_ids = [\"67bc656ba74dd0c677da05c4\", \"67bc660f4f5474ec75a7cc37\"]\n",
    "stack_name = \"opt-steel-strength\"\n",
    "project_name = \"dr-workshop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_up(project_name: str, stack_name: str, program: callable) -> auto.Stack:\n",
    "    # create (or select if one already exists) a stack that uses our inline program\n",
    "    stack = auto.create_or_select_stack(\n",
    "        stack_name=stack_name, project_name=project_name, program=program\n",
    "    )\n",
    "\n",
    "    stack.refresh(on_output=print)\n",
    "\n",
    "    stack.up(on_output=print)\n",
    "    return stack\n",
    "\n",
    "\n",
    "def destroy_project(stack: auto.Stack):\n",
    "    \"\"\"Destroy pulumi project\"\"\"\n",
    "    stack_name = stack.name\n",
    "    stack.destroy(on_output=print)\n",
    "\n",
    "    stack.workspace.remove_stack(stack_name)\n",
    "    print(f\"stack {stack_name} in project removed\")\n",
    "\n",
    "\n",
    "def make_deployment():\n",
    "    \"\"\"Deploy a trained model onto DataRobot.\"\"\"\n",
    "    # ----- target 1 -----\n",
    "    registered_model_1 = datarobot.RegisteredModelFromLeaderboard(\n",
    "        resource_name=f\"[opt]-registered-model-{targets[0]}\",\n",
    "        model_id=model_ids[0],\n",
    "        name=f\"[opt]-registered-model-{targets[0]}\",\n",
    "        use_case_ids=[usecase_id],\n",
    "    )\n",
    "    registered_model_id_1 = registered_model_1.id\n",
    "    registered_model_version_id_1 = registered_model_1.version_id\n",
    "\n",
    "    # ----- target 1 quantile 0.25 -----\n",
    "    registered_model_quant_25 = datarobot.RegisteredModelFromLeaderboard(\n",
    "        resource_name=f\"[opt]-registered-model-{targets[0]}-quantile-0.25\",\n",
    "        model_id=model_quant_ids[0],\n",
    "        name=f\"[opt]-registered-model-{targets[0]}-quantile-0.25\",\n",
    "        use_case_ids=[usecase_id],\n",
    "    )\n",
    "    registered_model_quant_id_1 = registered_model_quant_25.id\n",
    "    registered_model_quant_version_id_1 = registered_model_quant_25.version_id\n",
    "\n",
    "    # ----- target 1 quantile 0.75 -----\n",
    "    registered_model_quant_75 = datarobot.RegisteredModelFromLeaderboard(\n",
    "        resource_name=f\"[opt]-registered-model-{targets[0]}-quantile-0.75\",\n",
    "        model_id=model_quant_ids[1],\n",
    "        name=f\"[opt]-registered-model-{targets[0]}-quantile-0.75\",\n",
    "        use_case_ids=[usecase_id],\n",
    "    )\n",
    "    registered_model_quant_id_2 = registered_model_quant_75.id\n",
    "    registered_model_quant_version_id_2 = registered_model_quant_75.version_id\n",
    "\n",
    "    # ----- target 2 -----\n",
    "    registered_model_2 = datarobot.RegisteredModelFromLeaderboard(\n",
    "        resource_name=f\"[opt]-registered-model-{targets[1]}\",\n",
    "        model_id=model_ids[1],\n",
    "        name=f\"[opt]-registered-model-{targets[1]}\",\n",
    "        use_case_ids=[usecase_id],\n",
    "    )\n",
    "    registered_model_id_2 = registered_model_2.id\n",
    "    registered_model_version_id_2 = registered_model_2.version_id\n",
    "\n",
    "    # ----- prediction environment -----\n",
    "    prediction_environment = datarobot.PredictionEnvironment(\n",
    "        resource_name=\"[opt]-prediction-environment\",\n",
    "        name=\"[opt]-prediction-environment\",\n",
    "        batch_jobs_max_concurrent=100,\n",
    "        platform=\"datarobotServerless\",\n",
    "        supported_model_formats=[\n",
    "            \"datarobot\",\n",
    "            # \"customModel\",\n",
    "        ],\n",
    "    )\n",
    "    prediction_environment_id = prediction_environment.id\n",
    "    # ----- deploy for target 1 -----\n",
    "    deployment_1 = datarobot.Deployment(\n",
    "        resource_name=f\"[opt]-deployment-{targets[0]}\",\n",
    "        label=f\"[opt]-deployment-{targets[0]}\",\n",
    "        registered_model_version_id=registered_model_version_id_1,\n",
    "        prediction_environment_id=prediction_environment_id,\n",
    "        drift_tracking_settings={\n",
    "            \"feature_drift_enabled\": False,\n",
    "            \"target_drift_enabled\": False,\n",
    "        },\n",
    "        association_id_settings={\n",
    "            \"auto_generate_id\": False,\n",
    "            \"column_names\": [\"association_id\"],\n",
    "            \"required_in_prediction_requests\": False,\n",
    "        },\n",
    "        predictions_data_collection_settings={\n",
    "            \"enabled\": True,\n",
    "        },\n",
    "        batch_monitoring_settings={\n",
    "            \"enabled\": False,\n",
    "        },\n",
    "        segment_analysis_settings={\n",
    "            \"enabled\": True,\n",
    "            \"attributes\": [],\n",
    "        },\n",
    "        use_case_ids=[usecase_id],\n",
    "    )\n",
    "    # ----- deploy for target 1 quantile 0.25 -----\n",
    "    deployment_quant_25 = datarobot.Deployment(\n",
    "        resource_name=f\"[opt]-deployment-{targets[0]}-quantile-0.25\",\n",
    "        label=f\"[opt]-deployment-{targets[0]}-quantile-0.25\",\n",
    "        registered_model_version_id=registered_model_quant_version_id_1,\n",
    "        prediction_environment_id=prediction_environment_id,\n",
    "        drift_tracking_settings={\n",
    "            \"feature_drift_enabled\": False,\n",
    "            \"target_drift_enabled\": False,\n",
    "        },\n",
    "        association_id_settings={\n",
    "            \"auto_generate_id\": False,\n",
    "            \"column_names\": [\"association_id\"],\n",
    "            \"required_in_prediction_requests\": False,\n",
    "        },\n",
    "        predictions_data_collection_settings={\n",
    "            \"enabled\": True,\n",
    "        },\n",
    "        batch_monitoring_settings={\n",
    "            \"enabled\": False,\n",
    "        },\n",
    "        segment_analysis_settings={\n",
    "            \"enabled\": True,\n",
    "            \"attributes\": [],\n",
    "        },\n",
    "        use_case_ids=[usecase_id],\n",
    "    )\n",
    "    # ----- deploy for target 1 quantile 0.75 -----\n",
    "    deployment_quant_75 = datarobot.Deployment(\n",
    "        resource_name=f\"[opt]-deployment-{targets[0]}-quantile-0.75\",\n",
    "        label=f\"[opt]-deployment-{targets[0]}-quantile-0.75\",\n",
    "        registered_model_version_id=registered_model_quant_version_id_2,\n",
    "        prediction_environment_id=prediction_environment_id,\n",
    "        drift_tracking_settings={\n",
    "            \"feature_drift_enabled\": False,\n",
    "            \"target_drift_enabled\": False,\n",
    "        },\n",
    "        association_id_settings={\n",
    "            \"auto_generate_id\": False,\n",
    "            \"column_names\": [\"association_id\"],\n",
    "            \"required_in_prediction_requests\": False,\n",
    "        },\n",
    "        predictions_data_collection_settings={\n",
    "            \"enabled\": True,\n",
    "        },\n",
    "        batch_monitoring_settings={\n",
    "            \"enabled\": False,\n",
    "        },\n",
    "        segment_analysis_settings={\n",
    "            \"enabled\": True,\n",
    "            \"attributes\": [],\n",
    "        },\n",
    "        use_case_ids=[usecase_id],\n",
    "    )\n",
    "\n",
    "    # ----- deploy for target 2 -----\n",
    "    deployment_2 = datarobot.Deployment(\n",
    "        resource_name=f\"[opt]-deployment-{targets[1]}\",\n",
    "        label=f\"[opt]-deployment-{targets[1]}\",\n",
    "        registered_model_version_id=registered_model_version_id_2,\n",
    "        prediction_environment_id=prediction_environment_id,\n",
    "        drift_tracking_settings={\n",
    "            \"feature_drift_enabled\": False,\n",
    "            \"target_drift_enabled\": False,\n",
    "        },\n",
    "        association_id_settings={\n",
    "            \"auto_generate_id\": False,\n",
    "            \"column_names\": [\"association_id\"],\n",
    "            \"required_in_prediction_requests\": False,\n",
    "        },\n",
    "        predictions_data_collection_settings={\n",
    "            \"enabled\": True,\n",
    "        },\n",
    "        batch_monitoring_settings={\n",
    "            \"enabled\": False,\n",
    "        },\n",
    "        segment_analysis_settings={\n",
    "            \"enabled\": True,\n",
    "            \"attributes\": [],\n",
    "        },\n",
    "        use_case_ids=[usecase_id],\n",
    "    )\n",
    "    pulumi.export(\"prediction_environment_id\", prediction_environment_id)\n",
    "    pulumi.export(f\"registered_model_id for {targets[0]}\", registered_model_id_1)\n",
    "    pulumi.export(\n",
    "        f\"registered_model_version_id for {targets[0]}\", registered_model_version_id_1\n",
    "    )\n",
    "    pulumi.export(f\"deployment_id for {targets[0]}\", deployment_1.id)\n",
    "    pulumi.export(f\"registered_model_id for {targets[1]}\", registered_model_id_2)\n",
    "    pulumi.export(\n",
    "        f\"registered_model_version_id for {targets[1]}\", registered_model_version_id_2\n",
    "    )\n",
    "    pulumi.export(f\"deployment_id for {targets[1]}\", deployment_2.id)\n",
    "    pulumi.export(\n",
    "        f\"registered_model_id for {targets[0]} quantile 0.25\",\n",
    "        registered_model_quant_id_1,\n",
    "    )\n",
    "    pulumi.export(\n",
    "        f\"registered_model_version_id for {targets[0]} quantile 0.25\",\n",
    "        registered_model_quant_version_id_1,\n",
    "    )\n",
    "    pulumi.export(\n",
    "        f\"deployment_id for {targets[0]} quantile 0.25\", deployment_quant_25.id\n",
    "    )\n",
    "    pulumi.export(\n",
    "        f\"registered_model_id for {targets[0]} quantile 0.75\",\n",
    "        registered_model_quant_id_2,\n",
    "    )\n",
    "    pulumi.export(\n",
    "        f\"registered_model_version_id for {targets[0]} quantile 0.75\",\n",
    "        registered_model_quant_version_id_2,\n",
    "    )\n",
    "    pulumi.export(\n",
    "        f\"deployment_id for {targets[0]} quantile 0.75\", deployment_quant_75.id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = stack_up(project_name, stack_name, program=make_deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = stack.outputs()\n",
    "deployment_id_1 = result[f\"deployment_id for {targets[0]}\"].value\n",
    "deployment_id_2 = result[f\"deployment_id for {targets[1]}\"].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack = auto.select_stack(\n",
    "#     stack_name=stack_name, project_name=project_name, program=make_deployment\n",
    "# )\n",
    "# destroy_project(stack)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
